% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  10pt,
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage[]{mathpazo}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading,figureheading}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Third Year Paper Proposal},
  pdfauthor={Benjamin Lira},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Third Year Paper Proposal}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Large Language Models make human coding in the social sciences
obsolete}
\author{Benjamin Lira}
\date{}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[interior hidden, breakable, enhanced, borderline west={3pt}{0pt}{shadecolor}, boxrule=0pt, sharp corners, frame hidden]}{\end{tcolorbox}}\fi

\setstretch{1}
\hypertarget{gap-in-knowledge}{%
\section{GAP in knowledge}\label{gap-in-knowledge}}

Few of the available papers have outcomes, so they are only evaluated on
how well they match the humans

Humans are turkers, easy to beat

Constructs are not complex psychological phenomena (e.g., personality,
emotions, etc. as opposed to sentiment)

No data on demographics, so what about bias

What about other languages

Existing tests on publicly available benchmarks may be affected by
contamination, that is the tests might be included in the training data
for these models\textsuperscript{\protect\hyperlink{ref-pangakis}{1}}.

\hypertarget{research-questions}{%
\section{Research Questions}\label{research-questions}}

\hypertarget{quality-of-ratings}{%
\subsection{Quality of ratings}\label{quality-of-ratings}}

\hypertarget{ratings-and-demographics}{%
\subsection{Ratings and Demographics}\label{ratings-and-demographics}}

\hypertarget{predictiveness-of-ratings}{%
\subsection{Predictiveness of Ratings}\label{predictiveness-of-ratings}}

\begin{itemize}
\tightlist
\item
  Does few shot performance produce better results than zero shot
  performance?
\end{itemize}

\hypertarget{ancilliary-questions}{%
\subsection{Ancilliary Questions}\label{ancilliary-questions}}

\begin{itemize}
\tightlist
\item
  Does few shot performance produce better results than zero shot
  performance?
\item
  How does GPT-4, GPT-3.5, and open source models compare
\item
  What effect does temperature have on rating quality
\item
  What effect does aggregating multiple ratings have on quality
\end{itemize}

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2500}}@{}}
\caption{Fruit prices}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Tables
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Are
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cool
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Tables
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Are
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cool
\end{minipage} \\
\midrule()
\endhead
col 1 is & left-aligned & \$1600 \\
col 2 is & centered & \$12 \\
\bottomrule()
\end{longtable}

\hypertarget{reading-list}{%
\section{Reading List}\label{reading-list}}

In the past weeks, multiple papers have emerged, discussing the
appropriateness of GPT for automated labelling and qualitative coding.
Below is a reading list, with some comments for each.

\textsuperscript{\protect\hyperlink{ref-pangakis}{1}} seems to be the
only article suggesting caution. They suggest that performance is not
uniform, depends on prompt quality, idiosincracies of the text data, and
the complexity of the constructs. Thus, they recommend always validating
against human ratings. They used 27 tasks in 11 datasets.\\
They also introduce the idea of a \emph{consistency score} obtained by
repeatedly applying ratings and evaluating distance to the modal
response. \texttt{temp\ =\ .6}

Reiss found negative results.

\textsuperscript{\protect\hyperlink{ref-kim}{2}}

\textsuperscript{\protect\hyperlink{ref-dillion2023}{3}}

\textsuperscript{\protect\hyperlink{ref-ziems}{4}} provides a thorough
investigation of LLMs for computational social science.

\textsuperscript{\protect\hyperlink{ref-sahu}{5}}

Rathje et al\textsuperscript{\protect\hyperlink{ref-rathje}{6}} has
probably written the paper closest to the paper I wanted to write. They
focus not just on sentiment but also on discrete emotions. They compare
the accuracy of LLMs (.66 - .75) to that of LIWC (.20 - .30). It seems
like they obtain good results mostly because they are rating simple
constructs (sentiment, discrete emotions, and offensiveness) in short
texts (mostly tweets)

\textsuperscript{\protect\hyperlink{ref-ding}{7}}

\textsuperscript{\protect\hyperlink{ref-liu}{8}}

\textsuperscript{\protect\hyperlink{ref-wang2021}{9}}

To add: Gilardi (2023), Reiss (2023), He et al (23), Zhu (23)

\hypertarget{some-notes-of-caution}{%
\section{Some notes of caution}\label{some-notes-of-caution}}

I wonder if it this is a project worth pursuing. Below is a list of
potential problems.

\begin{itemize}
\tightlist
\item
  While the project seemed like a good idea when it came about, the
  space has quickly saturated and what seemed like a big contribution
  has now been covered in parts by the multitude of papers cited here.
  Thus, the size of the contribution gets smaller by the day.
\item
  This is not an \textbf{evergreen} research question. Soon GPT-5 will
  be out and the answers will be outdated. Thus, the relevance of the
  contribution gets smaller by the day.
\item
  It is difficult to find enough datasets that match inclusion criteria.
\end{itemize}

\hypertarget{extra-notes-to-self}{%
\section{Extra notes to self}\label{extra-notes-to-self}}

\begin{itemize}
\tightlist
\item
  Making every classification binary can be helpful to standardize
  performance. E.g., don't do multiclass or multilabel classification.
\end{itemize}

Large language models (LLMs) are neural networks that are trained on
massive amounts of text data and can generate natural language in
response to various inputs. LLMs have shown remarkable capabilities in
natural language understanding and generation tasks, such as question
answering, summarization, and text classification. However, most LLMs
are trained on data that is predominantly in English, which may limit
their ability to handle other languages and domains.

Few-shot learning is a paradigm that aims to leverage the prior
knowledge of LLMs to perform new tasks with minimal supervision. In
few-shot learning, the LLM is given a few labeled examples of a new
task, along with a natural language prompt that describes the task. The
LLM then uses its generative power to produce an answer for the task.
Few-shot learning has been applied to various natural language
processing tasks, such as sentiment analysis, relation extraction, and
named entity recognition.

However, few-shot learning with LLMs has not been extensively explored
for the task of classifying psychological constructs from open-ended
text. Psychological constructs are abstract concepts that are used to
describe and measure human behavior and mental processes, such as
personality traits, emotions, attitudes, and motivations. Classifying
psychological constructs from text is a challenging task that requires a
deep understanding of the meaning and context of the text, as well as
the theoretical and empirical foundations of the constructs.

Classifying psychological constructs from text has many potential
applications in psychology and related fields, such as education,
health, and social sciences. For example, classifying text responses to
personality questionnaires can help assess individual differences and
predict outcomes. Classifying text responses to surveys or interviews
can help measure attitudes and opinions on various topics. Classifying
text responses to prompts or scenarios can help elicit emotions and
motivations.

However, classifying psychological constructs from text also poses
several challenges and limitations. First, there is no consensus on the
definition and measurement of many psychological constructs, which may
lead to ambiguity and inconsistency in the labels. Second, there is
often a lack of large-scale labeled data for many psychological
constructs, which may limit the performance of supervised learning
methods. Third, there may be ethical and social implications of using
LLMs to classify psychological constructs from text, such as privacy,
bias, and fairness.

Therefore, in this paper, we aim to investigate the following research
questions:

\begin{itemize}
\tightlist
\item
  How do LLMs perform in few-shot classification of psychological
  constructs from open-ended text?
\item
  How do LLMs compare to human annotators in terms of accuracy and
  reliability?
\item
  How do LLMs relate to outcomes such as behavior, performance, or
  well-being?
\item
  How do LLMs relate to demographics such as age, gender, or ethnicity?
  Do LLMs exhibit any bias or discrimination in their classifications?
\end{itemize}

To answer these questions, we use a set of articles that cover various
psychological constructs and domains. We use a standard few-shot
learning framework with natural language prompts to classify the text
responses into predefined categories. We evaluate the performance of
LLMs against human annotators and baseline methods. We also analyze the
correlations between LLM classifications and outcomes and demographics.

We hope that this paper will contribute to the literature on few-shot
learning with LLMs and provide insights into the potential and
limitations of using LLMs for classifying psychological constructs from
text.

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-pangakis}{}}%
1. Pangakis, N., Wolken, S., \& Fasching, N. (n.d.). \emph{Automated
Annotation with Generative AI Requires Validation}.

\leavevmode\vadjust pre{\hypertarget{ref-kim}{}}%
2. Kim, J., \& Lee, B. (n.d.). \emph{AI-augmented surveys: Leveraging
large language models for opinion prediction in nationally
representative surveys}.

\leavevmode\vadjust pre{\hypertarget{ref-dillion2023}{}}%
3. Dillion, D., Tandon, N., Gu, Y., \& Gray, K. (2023). Can AI language
models replace human participants? \emph{Trends in Cognitive Sciences},
\emph{27}(7), 597--600. \url{https://doi.org/10.1016/j.tics.2023.04.008}

\leavevmode\vadjust pre{\hypertarget{ref-ziems}{}}%
4. Ziems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., \& Yang, D.
(n.d.). \emph{Can Large Language Models Transform Computational Social
Science?}

\leavevmode\vadjust pre{\hypertarget{ref-sahu}{}}%
5. Sahu, G., Rodriguez, P., Laradji, I. H., Atighehchian, P., Vazquez,
D., \& Bahdanau, D. (n.d.). \emph{Data augmentation for intent
classification with off-the-shelf large language models}.

\leavevmode\vadjust pre{\hypertarget{ref-rathje}{}}%
6. Rathje, S., Mirea, D.-M., Sucholutsky, I., Marjieh, R., Robertson,
C., \& Bavel, J. J. V. (n.d.). \emph{GPT is an effective tool for
multilingual psychological text analysis}.
\url{https://doi.org/10.31234/osf.io/sekf5}

\leavevmode\vadjust pre{\hypertarget{ref-ding}{}}%
7. Ding, B., Qin, C., Liu, L., Chia, Y. K., Joty, S., Li, B., \& Bing,
L. (n.d.). \emph{Is GPT-3 a good data annotator?}

\leavevmode\vadjust pre{\hypertarget{ref-liu}{}}%
8. Liu, D. L. (n.d.). \emph{Professor Bryony Hoskins University of
Roehampton, London, U.K.} 108.

\leavevmode\vadjust pre{\hypertarget{ref-wang2021}{}}%
9. Wang, S., Liu, Y., Xu, Y., Zhu, C., \& Zeng, M. (2021).
\emph{Findings 2021}. 41954205.
\url{https://doi.org/10.18653/v1/2021.findings-emnlp.354}

\end{CSLReferences}



\end{document}
